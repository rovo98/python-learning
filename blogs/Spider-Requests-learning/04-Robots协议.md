### Robots协议

Robots Exclusion Standard 网络爬虫排除标准

作用： 网站告知爬虫那些页面可以爬取，那些不行

形式：在网站根目录下的robots.txt文件。

#### 1.Robots协议的使用
- 网络爬虫：自动或人工识别robots.txt, 再进行内容爬取
- 约束性：Robots协议是建议但非约束性，网络爬虫可以不遵守，但存在法律风险
- Robots协议的语法：
  ```python
  # 注释， * 代表所有， /代表根目录
  User-agent: *
  Disallow: /
  ```
#### 2.对Robots协议的理解

| 访问量很小：可以遵守   访问量较大：建议遵守 | 非商业且偶尔：建议遵守   商业利益：必须遵守 | 必须遵守 |
| :---------------------: | :---------------------: | :--: |
|        爬取网页 玩转网页        |       爬取网站 爬取系列网站       | 爬取全网 |
